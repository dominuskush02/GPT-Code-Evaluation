import openai
from tenacity import retry, stop_after_attempt, wait_exponential

openai.api_key = 'OPEN API KEY'
N_RETRIES = 3
TEMPERATURE = 0.5
SYSTEM_PROMPTS = {
    'baseline': """
        Your job is to rank the quality of two code snippets generated by ChatGPT in terms of expected runtime performance.
        The two code snippets are generated solutions to a StackOverflow problem involving either arrays or linked lists. The
        code snippets will be written in python. Rank them by expected runtime performance. If code snippet 1 is clearly faster, 
        respond with 'Answer: 1'. If code snippet 2 is clearly faster, respond with 'Answer: 2'. If neither solution is noticeably 
        superior to the other, respond with 'Answer: draw'. Keep in mind that you are a very harsh critic. Be fair and unbiased 
        in your judgement.
    """,
    'no_draws': """
        Your job is to rank the quality of two code snippets generated by ChatGPT in terms of expected runtime performance.
        The two code snippets are generated solutions to a StackOverflow problem involving either arrays or linked lists. The
        code snippets will be written in python. Rank them by expected runtime performance. If code snippet 1 is faster, respond 
        with 'Answer: 1'. If code snippet 2 is faster, respond with 'Answer: 2'. If you think they are the same, you must still choose 
        one so make your best guess. Be fair and unbiased in your judgement.
    """,
    'cot': """
        Your job is to rank the quality of two code snippets generated by ChatGPT in terms of expected runtime performance.
        The two code snippets are generated solutions to a StackOverflow problem involving either arrays or linked lists. The
        code snippets will be written in python. Think step-by-step to perform a time complexity analysis on each solution, then 
        rank them by expected runtime performance. If code snippet 1 is clearly faster in your analysis, end your response with 
        'Answer: 1'. If code snippet 2 is clearly faster, end your response with 'Answer: 2'. If neither solution is noticeably 
        superior to the other, end your response with 'Answer: draw'. Keep in mind that you are a very harsh critic. Be fair and 
        unbiased in your judgement.
    """
}

# Usage notes: basically just pass in the two solutions and an index for which system prompt you want
# Adjust constants up top. Prompt indices are defined in SYSTEM_PROMPTS
# Instructed to include the substring 'Answer: X' in the response, so regex parsing will be easy

@retry(stop=stop_after_attempt(N_RETRIES), wait=wait_exponential(multiplier=1, min=4, max=70))
def compare(snippet1, snippet2, prompt_index):
    response = openai.ChatCompletion.create(
        model = 'gpt-4',
        messages = [
                {'role': 'system', 'content': SYSTEM_PROMPTS[prompt_index]},
                {'role': 'user', 'content':  f"""Snippet 1: {snippet1}\nSnippet 2: {snippet2}"""}
            ],

        temperature = TEMPERATURE
    )
    return response['choices'][0]['message']['content']